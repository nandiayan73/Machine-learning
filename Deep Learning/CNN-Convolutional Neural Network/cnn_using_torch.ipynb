{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial image size: Width: 150, Height: 149\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "import os\n",
    "from PIL import Image\n",
    "train_dir = 'dataset/training_set'\n",
    "test_dir = 'dataset/test_set'\n",
    "\n",
    "# Check the size of the first image in the dataset\n",
    "first_image_path = os.path.join(train_dir, 'cats', os.listdir(os.path.join(train_dir, 'cats'))[4])\n",
    "with Image.open(first_image_path) as img:\n",
    "    width, height = img.size\n",
    "    print(f\"Initial image size: Width: {width}, Height: {height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms={\n",
    "    'train':transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Resize((64,64)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                ]),\n",
    "    'test':transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Resize((64,64)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                                )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(train_dir, transform=data_transforms['train']),\n",
    "    'test': datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "}\n",
    "\n",
    "# Create dataloaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True),\n",
    "    'test': DataLoader(image_datasets['test'], batch_size=32, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "# for (inputs,labels) in dataloaders['train']:\n",
    "#     print(labels)\n",
    "#     img = inputs[0]  # Selecting the first image from the batch\n",
    "#     img = img.permute(1, 2, 0)  # Adjust dimensions from (C, H, W) to (H, W, C) for matplotlib\n",
    "#     plt.imshow(img.numpy())  # Plot the image\n",
    "#     plt.show()\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
